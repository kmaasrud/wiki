<!DOCTYPE HTML>
<html>
<head>
<title>Bayesian information criterion</title>
<meta charset="UTF-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#ffffff" />
<!-- Normalize -->
<link rel="stylesheet" href="css/normalize.min.css">
<!-- Prism -->
<link rel="stylesheet" href="css/prism.min.css">
<script src="js/prism.min.js"></script>
<!-- KaTeX -->
<link rel="stylesheet" href="css/katex.min.css">
<script src="js/katex.min.js"></script>
<script src="js/auto-render.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
renderMathInElement(document.body, {
delimiters: [
{left: '$$', right: '$$', display: true},
{left: '$', right: '$', display: false},
{left: '\\(', right: '\\)', display: false},
{left: '\\[', right: '\\]', display: true}
],
});
});
</script>
<!-- mdzk stylesheet -->
<link rel="stylesheet" href="css/mdzk.css">
</head>
<body>
<main>
<header>

<h1>Bayesian information criterion</h1>
</header>
<article>
<p>The <strong>Bayesian information criterion</strong> (BIC) or <strong>Schwarz information criterion</strong> (SIC) is a criterion for model selection in a finite set of models. We prefer the model with the lowest BIC. Its general defenition is<sup class="footnote-reference"><a href="#stat-learning">1</a></sup></p>
<p>$$ \text{BIC} = \log N\cdot d - 2\ \text{loglik} ,$$</p>
<p>where $N$ is the number of data points $d$ is the number of parameters estimated by the model and $\text{loglik}$ is the log of the maximized <a href="Likelihood%20function.html">likelihood function</a>.</p>
<div class="footnote-definition" id="stat-learning"><sup class="footnote-definition-label">1</sup>
<p><a href="Bibliography/The%20elements%20of%20statistical%20learning.html">The elements of statistical learning</a></p>
</div>

</article>
<footer class="backlinks">
<p>

</p>
</footer>
</main>
</body>
</html>